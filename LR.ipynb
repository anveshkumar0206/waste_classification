{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Path to the uploaded dataset zip file\n",
        "zip_path = '/content/dataset-resized.zip'\n",
        "\n",
        "# Temporary extraction path\n",
        "extraction_path = 'path_to_extraction_folder'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_path)\n",
        "\n",
        "# Define the path to the dataset folder\n",
        "dataset_folder = os.path.join(extraction_path, \"dataset-resized\")\n",
        "\n",
        "# List of categories (folder names)\n",
        "categories = [dir_name for dir_name in os.listdir(dataset_folder) if not dir_name.startswith('.')]\n",
        "\n",
        "# Initialize lists to store image data and labels\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "# Define desired size of images (example: 128x128 pixels)\n",
        "image_size = (128, 128)\n",
        "\n",
        "# Loop through each category\n",
        "for category in categories:\n",
        "    category_folder = os.path.join(dataset_folder, category)\n",
        "    print(f\"Processing category: {category}\")\n",
        "\n",
        "    # Loop through each image file in the category folder\n",
        "    for filename in tqdm(os.listdir(category_folder), desc=f\"Loading {category}\"):\n",
        "        image_path = os.path.join(category_folder, filename)\n",
        "\n",
        "        # Open the image using PIL and resize it\n",
        "        with Image.open(image_path) as img:\n",
        "            img_resized = img.resize(image_size)\n",
        "\n",
        "        # Convert the image to a numpy array and normalize it\n",
        "        image_array = np.array(img_resized) / 255.0\n",
        "\n",
        "        # Append the processed image data and label to the lists\n",
        "        data.append(image_array)\n",
        "        labels.append(category)\n",
        "\n",
        "# Convert lists to numpy arrays for machine learning processing\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Convert labels to numerical values using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, encoded_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# You can now proceed with training your machine learning model\n",
        "print(\"Data and labels prepared. Ready for model training.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5Ofekv3RP2d",
        "outputId": "57bb4eb4-94b8-4282-820a-42c399442a13"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing category: paper\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading paper: 100%|██████████| 594/594 [00:02<00:00, 200.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing category: cardboard\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cardboard: 100%|██████████| 403/403 [00:02<00:00, 188.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing category: trash\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading trash: 100%|██████████| 137/137 [00:00<00:00, 245.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing category: plastic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading plastic: 100%|██████████| 482/482 [00:01<00:00, 267.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing category: metal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading metal: 100%|██████████| 410/410 [00:01<00:00, 267.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing category: glass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading glass: 100%|██████████| 501/501 [00:01<00:00, 271.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data and labels prepared. Ready for model training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Corrected path to the dataset folder after extraction\n",
        "base_path = '/content/path_to_extraction_folder/dataset-resized'  # Adjusted path\n",
        "\n",
        "# Categories of the images\n",
        "Categories = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
        "\n",
        "# Initialize lists to store flattened image data and corresponding labels\n",
        "flat_data_arr = []\n",
        "target_arr = []\n",
        "\n",
        "# Loop through each category\n",
        "for i in Categories:\n",
        "    print(f'Loading... category : {i}')\n",
        "    path = os.path.join(base_path, i)\n",
        "\n",
        "    # Ensure the path exists before processing\n",
        "    if os.path.exists(path):\n",
        "        # Loop through each image file in the category folder\n",
        "        for img in tqdm(os.listdir(path), desc=f'Loading {i}'):\n",
        "            img_path = os.path.join(path, img)\n",
        "\n",
        "            # Read the image, resize it to 150x150 pixels, and normalize the pixel values\n",
        "            img_array = imread(img_path)\n",
        "            img_resized = resize(img_array, (150, 150, 3))\n",
        "\n",
        "            # Flatten the resized image and append it to the list, along with the label\n",
        "            flat_data_arr.append(img_resized.flatten())\n",
        "            target_arr.append(Categories.index(i))\n",
        "\n",
        "        print(f'Loaded category: {i} successfully')\n",
        "    else:\n",
        "        print(f\"Path does not exist: {path}\")\n",
        "\n",
        "# Convert lists to numpy arrays for further processing\n",
        "flat_data = np.array(flat_data_arr)\n",
        "target = np.array(target_arr)\n",
        "\n",
        "# Create a DataFrame with the flattened image data\n",
        "df = pd.DataFrame(flat_data)\n",
        "\n",
        "# Add the target labels to the DataFrame\n",
        "df['Target'] = target\n",
        "df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "id": "vtEXvKorSJpn",
        "outputId": "a3008904-7c26-4ab9-8435-68ea25c25bd9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading... category : cardboard\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cardboard: 100%|██████████| 403/403 [00:09<00:00, 43.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded category: cardboard successfully\n",
            "Loading... category : glass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading glass: 100%|██████████| 501/501 [00:12<00:00, 40.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded category: glass successfully\n",
            "Loading... category : metal\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading metal: 100%|██████████| 410/410 [00:10<00:00, 40.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded category: metal successfully\n",
            "Loading... category : paper\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading paper: 100%|██████████| 594/594 [00:18<00:00, 32.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded category: paper successfully\n",
            "Loading... category : plastic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading plastic: 100%|██████████| 482/482 [00:14<00:00, 33.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded category: plastic successfully\n",
            "Loading... category : trash\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading trash: 100%|██████████| 137/137 [00:03<00:00, 34.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded category: trash successfully\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "0     1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
              "1     0.972549  0.835294  0.709804  0.972636  0.835381  0.709891  0.977250   \n",
              "2     0.838479  0.720832  0.587499  0.834761  0.717114  0.583780  0.825568   \n",
              "3     0.711760  0.352731  0.242158  0.825364  0.652418  0.556024  0.800122   \n",
              "4     0.752532  0.576061  0.462336  0.752410  0.575939  0.462214  0.744871   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2522  0.886275  0.811765  0.752941  0.886275  0.811765  0.752941  0.886275   \n",
              "2523  0.854902  0.780392  0.721569  0.854902  0.780392  0.721569  0.854902   \n",
              "2524  0.940949  0.878203  0.827223  0.942480  0.879735  0.828755  0.934927   \n",
              "2525  0.764766  0.647119  0.603982  0.764849  0.647202  0.604065  0.770005   \n",
              "2526  0.925490  0.866667  0.784314  0.925532  0.866709  0.784356  0.928130   \n",
              "\n",
              "             7         8         9  ...     67491     67492     67493  \\\n",
              "0     1.000000  1.000000  1.000000  ...  0.639704  0.514214  0.365194   \n",
              "1     0.839995  0.714505  0.972150  ...  0.473269  0.394838  0.288955   \n",
              "2     0.707920  0.574587  0.824405  ...  0.586051  0.554679  0.464483   \n",
              "3     0.728429  0.663315  0.782666  ...  0.229110  0.127150  0.066609   \n",
              "4     0.568401  0.454675  0.740665  ...  0.987297  0.966396  0.990784   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "2522  0.811765  0.752941  0.886272  ...  0.324208  0.284993  0.237934   \n",
              "2523  0.780392  0.721569  0.854902  ...  0.375047  0.327989  0.273087   \n",
              "2524  0.872181  0.821201  0.929513  ...  0.854902  0.800000  0.756863   \n",
              "2525  0.652358  0.609221  0.772543  ...  0.588666  0.502392  0.451411   \n",
              "2526  0.869306  0.786953  0.929406  ...  0.338517  0.303223  0.244400   \n",
              "\n",
              "         67494     67495     67496     67497     67498     67499  Target  \n",
              "0     0.637421  0.511931  0.362912  0.639127  0.513637  0.364617       0  \n",
              "1     0.465564  0.387133  0.281251  0.463920  0.385489  0.279607       0  \n",
              "2     0.588217  0.556844  0.466648  0.569235  0.537863  0.447667       0  \n",
              "3     0.242783  0.141565  0.072756  0.254131  0.155960  0.077926       0  \n",
              "4     0.989720  0.960126  0.988277  0.995813  0.956995  0.988235       0  \n",
              "...        ...       ...       ...       ...       ...       ...     ...  \n",
              "2522  0.321611  0.282395  0.235336  0.321569  0.282353  0.235294       5  \n",
              "2523  0.367348  0.320289  0.265387  0.358793  0.311734  0.256832       5  \n",
              "2524  0.854902  0.800000  0.756863  0.854902  0.800000  0.756863       5  \n",
              "2525  0.581770  0.495495  0.444515  0.567210  0.480936  0.429955       5  \n",
              "2526  0.341075  0.305781  0.246957  0.341117  0.305822  0.246999       5  \n",
              "\n",
              "[2527 rows x 67501 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79cf905c-478c-460b-b698-4f38ed90a900\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>67491</th>\n",
              "      <th>67492</th>\n",
              "      <th>67493</th>\n",
              "      <th>67494</th>\n",
              "      <th>67495</th>\n",
              "      <th>67496</th>\n",
              "      <th>67497</th>\n",
              "      <th>67498</th>\n",
              "      <th>67499</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.639704</td>\n",
              "      <td>0.514214</td>\n",
              "      <td>0.365194</td>\n",
              "      <td>0.637421</td>\n",
              "      <td>0.511931</td>\n",
              "      <td>0.362912</td>\n",
              "      <td>0.639127</td>\n",
              "      <td>0.513637</td>\n",
              "      <td>0.364617</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.972549</td>\n",
              "      <td>0.835294</td>\n",
              "      <td>0.709804</td>\n",
              "      <td>0.972636</td>\n",
              "      <td>0.835381</td>\n",
              "      <td>0.709891</td>\n",
              "      <td>0.977250</td>\n",
              "      <td>0.839995</td>\n",
              "      <td>0.714505</td>\n",
              "      <td>0.972150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.473269</td>\n",
              "      <td>0.394838</td>\n",
              "      <td>0.288955</td>\n",
              "      <td>0.465564</td>\n",
              "      <td>0.387133</td>\n",
              "      <td>0.281251</td>\n",
              "      <td>0.463920</td>\n",
              "      <td>0.385489</td>\n",
              "      <td>0.279607</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.838479</td>\n",
              "      <td>0.720832</td>\n",
              "      <td>0.587499</td>\n",
              "      <td>0.834761</td>\n",
              "      <td>0.717114</td>\n",
              "      <td>0.583780</td>\n",
              "      <td>0.825568</td>\n",
              "      <td>0.707920</td>\n",
              "      <td>0.574587</td>\n",
              "      <td>0.824405</td>\n",
              "      <td>...</td>\n",
              "      <td>0.586051</td>\n",
              "      <td>0.554679</td>\n",
              "      <td>0.464483</td>\n",
              "      <td>0.588217</td>\n",
              "      <td>0.556844</td>\n",
              "      <td>0.466648</td>\n",
              "      <td>0.569235</td>\n",
              "      <td>0.537863</td>\n",
              "      <td>0.447667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.711760</td>\n",
              "      <td>0.352731</td>\n",
              "      <td>0.242158</td>\n",
              "      <td>0.825364</td>\n",
              "      <td>0.652418</td>\n",
              "      <td>0.556024</td>\n",
              "      <td>0.800122</td>\n",
              "      <td>0.728429</td>\n",
              "      <td>0.663315</td>\n",
              "      <td>0.782666</td>\n",
              "      <td>...</td>\n",
              "      <td>0.229110</td>\n",
              "      <td>0.127150</td>\n",
              "      <td>0.066609</td>\n",
              "      <td>0.242783</td>\n",
              "      <td>0.141565</td>\n",
              "      <td>0.072756</td>\n",
              "      <td>0.254131</td>\n",
              "      <td>0.155960</td>\n",
              "      <td>0.077926</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.752532</td>\n",
              "      <td>0.576061</td>\n",
              "      <td>0.462336</td>\n",
              "      <td>0.752410</td>\n",
              "      <td>0.575939</td>\n",
              "      <td>0.462214</td>\n",
              "      <td>0.744871</td>\n",
              "      <td>0.568401</td>\n",
              "      <td>0.454675</td>\n",
              "      <td>0.740665</td>\n",
              "      <td>...</td>\n",
              "      <td>0.987297</td>\n",
              "      <td>0.966396</td>\n",
              "      <td>0.990784</td>\n",
              "      <td>0.989720</td>\n",
              "      <td>0.960126</td>\n",
              "      <td>0.988277</td>\n",
              "      <td>0.995813</td>\n",
              "      <td>0.956995</td>\n",
              "      <td>0.988235</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2522</th>\n",
              "      <td>0.886275</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.886275</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.886275</td>\n",
              "      <td>0.811765</td>\n",
              "      <td>0.752941</td>\n",
              "      <td>0.886272</td>\n",
              "      <td>...</td>\n",
              "      <td>0.324208</td>\n",
              "      <td>0.284993</td>\n",
              "      <td>0.237934</td>\n",
              "      <td>0.321611</td>\n",
              "      <td>0.282395</td>\n",
              "      <td>0.235336</td>\n",
              "      <td>0.321569</td>\n",
              "      <td>0.282353</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2523</th>\n",
              "      <td>0.854902</td>\n",
              "      <td>0.780392</td>\n",
              "      <td>0.721569</td>\n",
              "      <td>0.854902</td>\n",
              "      <td>0.780392</td>\n",
              "      <td>0.721569</td>\n",
              "      <td>0.854902</td>\n",
              "      <td>0.780392</td>\n",
              "      <td>0.721569</td>\n",
              "      <td>0.854902</td>\n",
              "      <td>...</td>\n",
              "      <td>0.375047</td>\n",
              "      <td>0.327989</td>\n",
              "      <td>0.273087</td>\n",
              "      <td>0.367348</td>\n",
              "      <td>0.320289</td>\n",
              "      <td>0.265387</td>\n",
              "      <td>0.358793</td>\n",
              "      <td>0.311734</td>\n",
              "      <td>0.256832</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2524</th>\n",
              "      <td>0.940949</td>\n",
              "      <td>0.878203</td>\n",
              "      <td>0.827223</td>\n",
              "      <td>0.942480</td>\n",
              "      <td>0.879735</td>\n",
              "      <td>0.828755</td>\n",
              "      <td>0.934927</td>\n",
              "      <td>0.872181</td>\n",
              "      <td>0.821201</td>\n",
              "      <td>0.929513</td>\n",
              "      <td>...</td>\n",
              "      <td>0.854902</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.756863</td>\n",
              "      <td>0.854902</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.756863</td>\n",
              "      <td>0.854902</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.756863</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2525</th>\n",
              "      <td>0.764766</td>\n",
              "      <td>0.647119</td>\n",
              "      <td>0.603982</td>\n",
              "      <td>0.764849</td>\n",
              "      <td>0.647202</td>\n",
              "      <td>0.604065</td>\n",
              "      <td>0.770005</td>\n",
              "      <td>0.652358</td>\n",
              "      <td>0.609221</td>\n",
              "      <td>0.772543</td>\n",
              "      <td>...</td>\n",
              "      <td>0.588666</td>\n",
              "      <td>0.502392</td>\n",
              "      <td>0.451411</td>\n",
              "      <td>0.581770</td>\n",
              "      <td>0.495495</td>\n",
              "      <td>0.444515</td>\n",
              "      <td>0.567210</td>\n",
              "      <td>0.480936</td>\n",
              "      <td>0.429955</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2526</th>\n",
              "      <td>0.925490</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.784314</td>\n",
              "      <td>0.925532</td>\n",
              "      <td>0.866709</td>\n",
              "      <td>0.784356</td>\n",
              "      <td>0.928130</td>\n",
              "      <td>0.869306</td>\n",
              "      <td>0.786953</td>\n",
              "      <td>0.929406</td>\n",
              "      <td>...</td>\n",
              "      <td>0.338517</td>\n",
              "      <td>0.303223</td>\n",
              "      <td>0.244400</td>\n",
              "      <td>0.341075</td>\n",
              "      <td>0.305781</td>\n",
              "      <td>0.246957</td>\n",
              "      <td>0.341117</td>\n",
              "      <td>0.305822</td>\n",
              "      <td>0.246999</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2527 rows × 67501 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79cf905c-478c-460b-b698-4f38ed90a900')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79cf905c-478c-460b-b698-4f38ed90a900 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79cf905c-478c-460b-b698-4f38ed90a900');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f17943d7-4d42-4762-9fcf-444001c9f6e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f17943d7-4d42-4762-9fcf-444001c9f6e6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f17943d7-4d42-4762-9fcf-444001c9f6e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB4QGZXUNQfD",
        "outputId": "a632c61f-3585-4c89-d5b2-98a02b6bfd30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5612648221343873\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   cardboard       0.72      0.72      0.72        75\n",
            "       glass       0.43      0.54      0.48        96\n",
            "       metal       0.55      0.44      0.49        85\n",
            "       paper       0.59      0.73      0.65       117\n",
            "     plastic       0.58      0.49      0.53       100\n",
            "       trash       0.47      0.21      0.29        33\n",
            "\n",
            "    accuracy                           0.56       506\n",
            "   macro avg       0.56      0.52      0.53       506\n",
            "weighted avg       0.56      0.56      0.55       506\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  3 10  4  4  0]\n",
            " [ 3 52  6 17 15  3]\n",
            " [ 5 20 37 13  6  4]\n",
            " [ 4 14  5 85  8  1]\n",
            " [ 5 21  6 19 49  0]\n",
            " [ 4 12  3  5  2  7]]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Function to extract color histograms from images\n",
        "def extract_color_histogram(image_path, bins=32):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    hist = [cv2.calcHist([image], [i], None, [bins], [0, 256]) for i in range(3)]\n",
        "    hist = np.concatenate([cv2.normalize(h, h).flatten() for h in hist])\n",
        "    return hist\n",
        "# Function to process images and extract features\n",
        "def process_images(base_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "    categories = os.listdir(base_path)\n",
        "    for category in categories:\n",
        "        if category == \".DS_Store\":\n",
        "            continue\n",
        "        category_path = os.path.join(base_path, category)\n",
        "        images = [os.path.join(category_path, img) for img in os.listdir(category_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        for image_path in images:\n",
        "            hist_features = extract_color_histogram(image_path)\n",
        "            features.append(hist_features)\n",
        "            labels.append(category)\n",
        "    return np.array(features), np.array(labels)\n",
        "# Extract features and labels from the dataset\n",
        "features, labels = process_images(base_path)\n",
        "# Convert labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
        "# Initialize the Logistic Regression classifier\n",
        "log_reg_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg_clf.fit(X_train, y_train)\n",
        "# Make predictions on the test set\n",
        "y_pred = log_reg_clf.predict(X_test)\n",
        "# Calculate accuracy and classification report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "# Display the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y10OigEHP_X1",
        "outputId": "aefe5f78-5fcc-472e-fb6d-e334827f426d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA Accuracy: 0.5553359683794467\n",
            "PCA Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   cardboard       0.72      0.73      0.73        75\n",
            "       glass       0.42      0.53      0.47        96\n",
            "       metal       0.55      0.41      0.47        85\n",
            "       paper       0.58      0.68      0.63       117\n",
            "     plastic       0.56      0.53      0.54       100\n",
            "       trash       0.58      0.21      0.31        33\n",
            "\n",
            "    accuracy                           0.56       506\n",
            "   macro avg       0.57      0.52      0.53       506\n",
            "weighted avg       0.56      0.56      0.55       506\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  3 10  4  4  0]\n",
            " [ 3 52  6 17 15  3]\n",
            " [ 5 20 37 13  6  4]\n",
            " [ 4 14  5 85  8  1]\n",
            " [ 5 21  6 19 49  0]\n",
            " [ 4 12  3  5  2  7]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Apply PCA to reduce the feature dimensionality\n",
        "pca = PCA(n_components=0.95)  # Adjust this to the desired variance ratio\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "# Initialize the Logistic Regression classifier\n",
        "log_reg_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_reg_clf.fit(X_train_pca, y_train)\n",
        "# Make predictions on the test set with PCA applied\n",
        "y_pred_pca = log_reg_clf.predict(X_test_pca)\n",
        "# Calculate accuracy and classification report\n",
        "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
        "report_pca = classification_report(y_test, y_pred_pca, target_names=label_encoder.classes_)\n",
        "print(\"PCA Accuracy:\", accuracy_pca)\n",
        "print(\"PCA Classification Report:\\n\", report_pca)\n",
        "# Display the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate sensitivity and specificity for each class\n",
        "sensitivity_per_class = []\n",
        "specificity_per_class = []\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    true_positives = conf_matrix[i, i]\n",
        "    false_negatives = np.sum(conf_matrix[i, :]) - true_positives\n",
        "    false_positives = np.sum(conf_matrix[:, i]) - true_positives\n",
        "    true_negatives = np.sum(conf_matrix) - true_positives - false_negatives - false_positives\n",
        "\n",
        "    sensitivity = true_positives / (true_positives + false_negatives)\n",
        "    specificity = true_negatives / (true_negatives + false_positives)\n",
        "\n",
        "    sensitivity_per_class.append(sensitivity)\n",
        "    specificity_per_class.append(specificity)\n",
        "\n",
        "# Calculate average sensitivity and specificity\n",
        "average_sensitivity = np.mean(sensitivity_per_class)\n",
        "average_specificity = np.mean(specificity_per_class)\n",
        "\n",
        "print(\"Average Sensitivity:\", average_sensitivity)\n",
        "print(\"Average Specificity:\", average_specificity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njVaFPaXXH3E",
        "outputId": "82e0bc70-59e2-4302-de09-0bde2ce3a108"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Sensitivity: 0.5209296204884439\n",
            "Average Specificity: 0.9095108357579401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5FG8SF2RZoz",
        "outputId": "07721024-2819-48ff-b4d5-e989475db9bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
            "Best Parameters: {'logistic_regression__C': 1.623776739188721, 'logistic_regression__class_weight': None, 'logistic_regression__solver': 'liblinear'}\n",
            "Accuracy: 0.6837944664031621\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "   cardboard       0.78      0.83      0.80        75\n",
            "       glass       0.61      0.65      0.63        96\n",
            "       metal       0.76      0.55      0.64        85\n",
            "       paper       0.71      0.80      0.75       117\n",
            "     plastic       0.65      0.69      0.67       100\n",
            "       trash       0.52      0.36      0.43        33\n",
            "\n",
            "    accuracy                           0.68       506\n",
            "   macro avg       0.67      0.65      0.65       506\n",
            "weighted avg       0.68      0.68      0.68       506\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "# Function to extract both RGB and HSV color histograms from images\n",
        "def extract_features(image_path, bins=32):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)  # Convert to HSV\n",
        "    # Calculate the histogram for RGB\n",
        "    rgb_hist = np.concatenate([cv2.calcHist([image], [i], None, [bins], [0, 256]).flatten() for i in range(3)])\n",
        "    # Calculate the histogram for HSV\n",
        "    hsv_hist = np.concatenate([cv2.calcHist([hsv_image], [i], None, [bins], [0, 256]).flatten() for i in range(3)])\n",
        "    # Concatenate RGB and HSV histograms into a single feature vector\n",
        "    feature_vector = np.concatenate((rgb_hist, hsv_hist))\n",
        "    return feature_vector\n",
        "# Function to process images and extract features\n",
        "def process_images(base_path, bins=32):\n",
        "    features = []\n",
        "    labels = []\n",
        "    categories = os.listdir(base_path)\n",
        "    for category in categories:\n",
        "        if category == \".DS_Store\" or category == '__MACOSX':\n",
        "            continue\n",
        "        category_path = os.path.join(base_path, category)\n",
        "        images = [os.path.join(category_path, img) for img in os.listdir(category_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        for image_path in images:\n",
        "            feature_vector = extract_features(image_path, bins)\n",
        "            features.append(feature_vector)\n",
        "            labels.append(category)\n",
        "    return np.array(features), np.array(labels)\n",
        "# Extract features and labels from the dataset\n",
        "features, labels = process_images(base_path)\n",
        "# Convert labels to numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)\n",
        "# Create a pipeline that includes scaling and logistic regression\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('logistic_regression', LogisticRegression(max_iter=1000))\n",
        "])\n",
        "# Define a range of hyperparameters for tuning\n",
        "parameters = {\n",
        "    'logistic_regression__C': np.logspace(-4, 4, 20),\n",
        "    'logistic_regression__class_weight': [None, 'balanced'],\n",
        "    'logistic_regression__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}\n",
        "# Initialize GridSearchCV with the pipeline and hyperparameter space\n",
        "grid_search = GridSearchCV(pipeline, parameters, cv=5, verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "# Retrieve the best hyperparameters and the corresponding best model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "# Make predictions using the best model\n",
        "y_pred = best_model.predict(X_test)\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
        "# Print the results\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "# Display the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5kUT9WONSnp",
        "outputId": "0aa9e710-6785-4d9c-fdce-71f3083fa180"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined model and metrics are saved at /content/combined_model_and_metrics.pkl.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "# Assuming 'pipeline' is your trained model and 'metrics_results' is your computed metrics.\n",
        "\n",
        "# Define the path for the combined pickle file\n",
        "combined_file_path = '/content/combined_model_and_metrics.pkl'\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(os.path.dirname(combined_file_path), exist_ok=True)\n",
        "\n",
        "# Combine the model and metrics into a dictionary\n",
        "combined_data = {\n",
        "    'model': pipeline,\n",
        "    'metrics': classification_report\n",
        "}\n",
        "\n",
        "# Save the combined data to a single pickle file\n",
        "with open(combined_file_path, 'wb') as combined_file:\n",
        "    pickle.dump(combined_data, combined_file)\n",
        "\n",
        "print(f'Combined model and metrics are saved at {combined_file_path}.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ra3H49yRP6YE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tVoS4lSRROVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}